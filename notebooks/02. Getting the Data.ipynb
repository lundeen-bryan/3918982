{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data\n",
    "\n",
    "Our data comes directly from the [John Hopkins COVID-19 Github repository][1], which tracks all deaths and cases from each country in the world as well as many regions within some countries. All of the data needed for this project is within the [time series][2] directory, which contains four CSV files that summarize the deaths and cases for the world and the USA. The repository uses the word \"confirmed\" to refer to cases.\n",
    "\n",
    "[1]: https://github.com/CSSEGISandData/COVID-19\n",
    "[2]: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data into a pandas DataFrame\n",
    "\n",
    "The pandas `read_csv` function can read in remote CSV files by passing it the URL. The exact URL on Github is a bit tricky. You must use the \"raw\" data file, which can be retrieved by clicking on the file name (taking you to the next page), then right-clicking the \"view raw\" or \"download\" button and copying the link. The image below shows the screen you'll see for the first CSV.\n",
    "\n",
    "![1]\n",
    "\n",
    "[1]: images/url_download.png"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming conventions\n",
    "\n",
    "Before we write any code, let's cover some naming conventions that we will use throughout the project.\n",
    "\n",
    "### `group`\n",
    "\n",
    "We will use the name `group` to refer to the two separate \"groups\" of data.\n",
    "\n",
    "* `\"world\"` - represents all data from each country\n",
    "* `\"usa\"` - represents all data from each US state\n",
    "\n",
    "### `kind`\n",
    "\n",
    "We will use the name `kind` to refer to the two different kinds of COVID-19 data.\n",
    "\n",
    "* `\"deaths\"`\n",
    "* `\"cases\"`\n",
    "\n",
    "\n",
    "### `area`\n",
    "\n",
    "Occasionally, we will refer to either a specific country or state with the name `area`.\n",
    "\n",
    "## Downloading the data\n",
    "\n",
    "Now that we have the URL, we can download the data with pandas. Complete the exercise below to download all four files as DataFrames."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that reads in a single CSV and returns it as a DataFrame. This function accepts a kind and group. Use the variable `DOWNLOAD_URL` in your solution. Make sure you look at the URL in the repo from above to determine what values `kind` and `group` refer to. You'll have to reassign their values in the function so that the URL is correct. For example, the function call `download_data(\"world\", \"deaths\")` should download [one of the files on this page](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DOWNLOAD_URL = (\n",
    "    \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/\"\n",
    "    \"master/csse_covid_19_data/csse_covid_19_time_series/\"\n",
    "    \"time_series_covid19_{kind}_{group}.csv\"\n",
    ")\n",
    "\n",
    "# Mapping of input values to desired output values for group and kind\n",
    "GROUP_MAPPING = {\n",
    "    \"usa\": \"US\",    # if param is \"US\" then name \"usa\"\n",
    "    \"world\": \"global\"  # if param is \"global\" then name \"world\"\n",
    "}\n",
    "\n",
    "KIND_MAPPING = {\n",
    "    \"cases\": \"confirmed\",  # if param is \"confirmed\" then name \"cases\"\n",
    "    \"deaths\": \"deaths\"  # if param is \"deaths\" then name \"deaths\"\n",
    "}\n",
    "\n",
    "def download_data(group, kind):\n",
    "    \"\"\"\n",
    "    Returns the dataframe of the dataset from the John Hopkins GitHub repo\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    group : \"world\" or \"usa\"\n",
    "\n",
    "    kind : \"cases\" or \"deaths\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataframe\n",
    "        The dataframe from the url\n",
    "    \"\"\"\n",
    "    # Map the input values to the desired output values using dictionaries\n",
    "    group = GROUP_MAPPING.get(group, \"global\")\n",
    "    kind = KIND_MAPPING.get(kind, \"deaths\")\n",
    "\n",
    "    url = DOWNLOAD_URL.format(kind=kind, group=group)\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>2/28/23</th>\n",
       "      <th>3/1/23</th>\n",
       "      <th>3/2/23</th>\n",
       "      <th>3/3/23</th>\n",
       "      <th>3/4/23</th>\n",
       "      <th>3/5/23</th>\n",
       "      <th>3/6/23</th>\n",
       "      <th>3/7/23</th>\n",
       "      <th>3/8/23</th>\n",
       "      <th>3/9/23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84001001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>...</td>\n",
       "      <td>230</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84001003</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>...</td>\n",
       "      <td>724</td>\n",
       "      <td>726</td>\n",
       "      <td>726</td>\n",
       "      <td>726</td>\n",
       "      <td>726</td>\n",
       "      <td>726</td>\n",
       "      <td>726</td>\n",
       "      <td>726</td>\n",
       "      <td>727</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84001005</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84001007</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.996421</td>\n",
       "      <td>-87.125115</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84001009</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>33.982109</td>\n",
       "      <td>-86.567906</td>\n",
       "      <td>...</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region  \\\n",
       "0  84001001   US  USA    840  1001.0  Autauga        Alabama             US   \n",
       "1  84001003   US  USA    840  1003.0  Baldwin        Alabama             US   \n",
       "2  84001005   US  USA    840  1005.0  Barbour        Alabama             US   \n",
       "3  84001007   US  USA    840  1007.0     Bibb        Alabama             US   \n",
       "4  84001009   US  USA    840  1009.0   Blount        Alabama             US   \n",
       "\n",
       "         Lat      Long_  ... 2/28/23  3/1/23  3/2/23  3/3/23  3/4/23  3/5/23  \\\n",
       "0  32.539527 -86.644082  ...     230     232     232     232     232     232   \n",
       "1  30.727750 -87.722071  ...     724     726     726     726     726     726   \n",
       "2  31.868263 -85.387129  ...     103     103     103     103     103     103   \n",
       "3  32.996421 -87.125115  ...     109     109     109     109     109     109   \n",
       "4  33.982109 -86.567906  ...     261     261     261     261     261     261   \n",
       "\n",
       "   3/6/23  3/7/23  3/8/23  3/9/23  \n",
       "0     232     232     232     232  \n",
       "1     726     726     727     727  \n",
       "2     103     103     103     103  \n",
       "3     109     109     109     109  \n",
       "4     261     261     261     261  \n",
       "\n",
       "[5 rows x 1155 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = download_data(\"usa\", \"deaths\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important information on exercises - please read!\n",
    "\n",
    "All of the exercises require you to complete the body of a function. All functions end with the `pass` keyword. **Delete** it and write your solution in the body of the function.\n",
    "\n",
    "Solutions for all exercises are found in the [solutions.py](solutions.py) file in this directory. You can open it up in your favorite editor, or just click the link to open it in your browser.\n",
    "\n",
    "In the code cell following each exercise, you will see a single line of code that imports the function from the solutions.py file. For example, `from solutions import download_data`. Running this statement will provide you with a version of the function that produces the correct output for the exercise.\n",
    "\n",
    "**Comment out the import line** if you want to use and test **your version** of the function completed above. I highly recommend completing the exercises on your own. Keep the import line uncommented if you do not attempt the exercise. \n",
    "\n",
    "**Always check the solutions!** Make sure to check the [solutions.py](solutions.py) file for each exercise, even if you are sure you answered it correctly. Verifying solutions is one of the best known methods for internalizing new material."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the `download_data` function\n",
    "\n",
    "Let's read in the world deaths file as a DataFrame and output the head to verify that it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/28/23</th>\n",
       "      <th>3/1/23</th>\n",
       "      <th>3/2/23</th>\n",
       "      <th>3/3/23</th>\n",
       "      <th>3/4/23</th>\n",
       "      <th>3/5/23</th>\n",
       "      <th>3/6/23</th>\n",
       "      <th>3/7/23</th>\n",
       "      <th>3/8/23</th>\n",
       "      <th>3/9/23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "      <td>7896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "      <td>3598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.50630</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.20270</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1933</td>\n",
       "      <td>1933</td>\n",
       "      <td>1933</td>\n",
       "      <td>1933</td>\n",
       "      <td>1933</td>\n",
       "      <td>1933</td>\n",
       "      <td>1933</td>\n",
       "      <td>1933</td>\n",
       "      <td>1933</td>\n",
       "      <td>1933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "3            NaN        Andorra  42.50630   1.521800        0        0   \n",
       "4            NaN         Angola -11.20270  17.873900        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
       "0        0        0        0        0  ...     7896    7896    7896    7896   \n",
       "1        0        0        0        0  ...     3598    3598    3598    3598   \n",
       "2        0        0        0        0  ...     6881    6881    6881    6881   \n",
       "3        0        0        0        0  ...      165     165     165     165   \n",
       "4        0        0        0        0  ...     1933    1933    1933    1933   \n",
       "\n",
       "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
       "0    7896    7896    7896    7896    7896    7896  \n",
       "1    3598    3598    3598    3598    3598    3598  \n",
       "2    6881    6881    6881    6881    6881    6881  \n",
       "3     165     165     165     165     165     165  \n",
       "4    1933    1933    1933    1933    1933    1933  \n",
       "\n",
       "[5 rows x 1147 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comment out the import line below if you attempted the exercise above\n",
    "# keep the line below if you did not attempt the exercise\n",
    "# from solutions import download_data \n",
    "df_world_deaths = download_data('world', 'deaths')\n",
    "df_world_deaths.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a another function which uses `download_data` to read in all four DataFrames.\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that reads in all four CSVs as DataFrames returning them in a dictionary. Use the group and kind separated by an underscore as the key (i.e. `\"world_deaths\"`). Use the `GROUPS` and `KINDS` variables in your solution.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS = (\"world\", \"usa\")\n",
    "KINDS = (\"deaths\", \"cases\")\n",
    "\n",
    "def read_all_data():\n",
    "    \"\"\"\n",
    "    Read in all four CSVs as DataFrames\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "\n",
    "    for group in GROUPS:\n",
    "        for kind in KINDS:\n",
    "            try:\n",
    "                data[f\"{group}_{kind}\"] = download_data(group, kind)\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred while reading data for {group} {kind}: {str(e)}\")\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to read in all of the data and output the head of two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>2/28/23</th>\n",
       "      <th>3/1/23</th>\n",
       "      <th>3/2/23</th>\n",
       "      <th>3/3/23</th>\n",
       "      <th>3/4/23</th>\n",
       "      <th>3/5/23</th>\n",
       "      <th>3/6/23</th>\n",
       "      <th>3/7/23</th>\n",
       "      <th>3/8/23</th>\n",
       "      <th>3/9/23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>209322</td>\n",
       "      <td>209340</td>\n",
       "      <td>209358</td>\n",
       "      <td>209362</td>\n",
       "      <td>209369</td>\n",
       "      <td>209390</td>\n",
       "      <td>209406</td>\n",
       "      <td>209436</td>\n",
       "      <td>209451</td>\n",
       "      <td>209451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>334391</td>\n",
       "      <td>334408</td>\n",
       "      <td>334408</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334427</td>\n",
       "      <td>334443</td>\n",
       "      <td>334457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>271441</td>\n",
       "      <td>271448</td>\n",
       "      <td>271463</td>\n",
       "      <td>271469</td>\n",
       "      <td>271469</td>\n",
       "      <td>271477</td>\n",
       "      <td>271477</td>\n",
       "      <td>271490</td>\n",
       "      <td>271494</td>\n",
       "      <td>271496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  2/28/23  3/1/23  3/2/23  3/3/23  \\\n",
       "0        0        0        0        0  ...   209322  209340  209358  209362   \n",
       "1        0        0        0        0  ...   334391  334408  334408  334427   \n",
       "2        0        0        0        0  ...   271441  271448  271463  271469   \n",
       "\n",
       "   3/4/23  3/5/23  3/6/23  3/7/23  3/8/23  3/9/23  \n",
       "0  209369  209390  209406  209436  209451  209451  \n",
       "1  334427  334427  334427  334427  334443  334457  \n",
       "2  271469  271477  271477  271490  271494  271496  \n",
       "\n",
       "[3 rows x 1147 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember to comment out the following line if you attempt the exercise\n",
    "# this is the last exercise with this warning\n",
    "# from solutions import read_all_data\n",
    "data = read_all_data()\n",
    "data['world_cases'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>2/28/23</th>\n",
       "      <th>3/1/23</th>\n",
       "      <th>3/2/23</th>\n",
       "      <th>3/3/23</th>\n",
       "      <th>3/4/23</th>\n",
       "      <th>3/5/23</th>\n",
       "      <th>3/6/23</th>\n",
       "      <th>3/7/23</th>\n",
       "      <th>3/8/23</th>\n",
       "      <th>3/9/23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84001001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>...</td>\n",
       "      <td>19732</td>\n",
       "      <td>19759</td>\n",
       "      <td>19759</td>\n",
       "      <td>19759</td>\n",
       "      <td>19759</td>\n",
       "      <td>19759</td>\n",
       "      <td>19759</td>\n",
       "      <td>19759</td>\n",
       "      <td>19790</td>\n",
       "      <td>19790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84001003</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>...</td>\n",
       "      <td>69641</td>\n",
       "      <td>69767</td>\n",
       "      <td>69767</td>\n",
       "      <td>69767</td>\n",
       "      <td>69767</td>\n",
       "      <td>69767</td>\n",
       "      <td>69767</td>\n",
       "      <td>69767</td>\n",
       "      <td>69860</td>\n",
       "      <td>69860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84001005</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>...</td>\n",
       "      <td>7451</td>\n",
       "      <td>7474</td>\n",
       "      <td>7474</td>\n",
       "      <td>7474</td>\n",
       "      <td>7474</td>\n",
       "      <td>7474</td>\n",
       "      <td>7474</td>\n",
       "      <td>7474</td>\n",
       "      <td>7485</td>\n",
       "      <td>7485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region  \\\n",
       "0  84001001   US  USA    840  1001.0  Autauga        Alabama             US   \n",
       "1  84001003   US  USA    840  1003.0  Baldwin        Alabama             US   \n",
       "2  84001005   US  USA    840  1005.0  Barbour        Alabama             US   \n",
       "\n",
       "         Lat      Long_  ... 2/28/23  3/1/23  3/2/23  3/3/23  3/4/23  3/5/23  \\\n",
       "0  32.539527 -86.644082  ...   19732   19759   19759   19759   19759   19759   \n",
       "1  30.727750 -87.722071  ...   69641   69767   69767   69767   69767   69767   \n",
       "2  31.868263 -85.387129  ...    7451    7474    7474    7474    7474    7474   \n",
       "\n",
       "   3/6/23  3/7/23  3/8/23  3/9/23  \n",
       "0   19759   19759   19790   19790  \n",
       "1   69767   69767   69860   69860  \n",
       "2    7474    7474    7485    7485  \n",
       "\n",
       "[3 rows x 1154 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['usa_cases'].head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data locally\n",
    "\n",
    "Since the raw data must be downloaded from the internet, let's save a copy of our current data to a local folder so that we have access to it immediately at any time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that accepts a dictionary of DataFrames and a directory name, and writes them to that directory as CSVs using the key as the filename. Pass the `kwargs` to the `to_csv` method.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def write_data(data, directory, **kwargs):\n",
    "    \"\"\"\n",
    "    Writes each raw data DataFrame to a file as a CSV\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dict\n",
    "        Dictionary of DataFrames\n",
    "\n",
    "    directory : str\n",
    "        Name of directory to save files, e.g., \"data/raw\"\n",
    "\n",
    "    kwargs : dict\n",
    "        Extra keyword arguments for the `to_csv` DataFrame method\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for key, df in data.items():\n",
    "        filename = f\"{key}.csv\"\n",
    "        filepath = os.path.join(directory, filename)\n",
    "\n",
    "        # Check if the file already exists\n",
    "        if os.path.isfile(filepath):\n",
    "            # Generate a unique filename by appending a numeric suffix to the previous file\n",
    "            suffix = 1\n",
    "            while True:\n",
    "                suffix_filename = f\"{key}_{suffix}.csv\"\n",
    "                suffix_filepath = os.path.join(directory, suffix_filename)\n",
    "                if not os.path.isfile(suffix_filepath):\n",
    "                    os.rename(filepath, suffix_filepath)\n",
    "                    print(f\"New file downloaded: {filename} (Old file renamed to: {suffix_filename})\")\n",
    "                    break\n",
    "                suffix += 1\n",
    "        else:\n",
    "            print(f\"New file downloaded: {filename}\")\n",
    "\n",
    "        df.to_csv(filepath, **kwargs)\n",
    "\n",
    "    print(f\"Data saved to {directory}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write those DataFrames as CSVs (without their index) to the \"data/raw\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New file downloaded: world_deaths.csv (Old file renamed to: world_deaths_1.csv)\n",
      "New file downloaded: world_cases.csv (Old file renamed to: world_cases_1.csv)\n",
      "New file downloaded: usa_deaths.csv (Old file renamed to: usa_deaths_1.csv)\n",
      "New file downloaded: usa_cases.csv (Old file renamed to: usa_cases_1.csv)\n",
      "Data saved to data/raw\n"
     ]
    }
   ],
   "source": [
    "# from solutions import write_data\n",
    "write_data(data, \"data/raw\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function similar to `download_data`, but have it read in the local data that we just saved. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_local_data(group, kind, directory):\n",
    "    \"\"\"\n",
    "    Read in one CSV as a DataFrame from the given directory\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group : \"world\" or \"usa\"\n",
    "    \n",
    "    kind : \"deaths\" or \"cases\"\n",
    "    \n",
    "    directory : string name of directory to save files i.e. \"data/raw\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solutions import read_local_data\n",
    "read_local_data('world', 'deaths', 'data/raw').head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function similar to `read_all_data`, but have it read in all of the local data that we just saved. The function name is `run` since we will be slowly adding all of our data cleaning and transformation steps to it in the next chapter.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    \"\"\"\n",
    "    Run all cleaning and transformation steps\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we verify that `run` works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solutions import run\n",
    "data = run()\n",
    "data['usa_deaths'].tail(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the section on downloading the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
